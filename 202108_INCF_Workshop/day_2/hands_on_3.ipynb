{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import nixio\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "%config InlineBackend.figure_formats = ['retina'] # only for users with a high resolution display "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Exercise 1: Enabling compression in the \"radar_trap\" data with images.\n",
    "\n",
    "1. Test for the effect of the compression  and compare the file sizes with and without compression.\n",
    "\n",
    "## Your solution"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Exercise 2: store data with calibration\n",
    "\n",
    "1. Use the example code from the tutorial and create the nix file. Close it properly.\n",
    "2. Reopen the file.\n",
    "3. Compare the ``original_data`` and the data re-read from the file by plotting them.\n",
    "4. What is the file size when you use either method? Can compression alone help?\n",
    "\n",
    "## Your solution"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Exercise 3: Let's test the effects of chunking on the write performance.\n",
    "\n",
    "1. Use the code below and extend it to test different chunk sizes (chunk_samples controls how many samples per channel at a time). **Note:** make sure to have the same total number of samples written. A good total number of samples is about 1Mio, start with chunk_samples > 100.\n",
    "2. Compare the write performance with and without compression.\n",
    "3. Select the \"optimal\" chunking strategy and test the read performance with slices of varying size.\n",
    "\n",
    "## Your solution\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "def record_data(samples, channels, dt):\n",
    "    data = np.zeros((samples, channels))\n",
    "    t = np.arange(samples) * dt\n",
    "    for i in range(channels):\n",
    "        phase = i * 2 * np.pi / channels\n",
    "        data[:, i] = np.sin(2 * np.pi * t + phase) + (np.random.randn(samples) * 0.1)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def write_nixfile(filename, chunk_samples=1000, number_of_channels= 10, dt=0.001, chunk_count=100, compression=nixio.Compression.No):\n",
    "    nixfile = nixio.File.open(filename, nixio.FileMode.Overwrite, compression=compression)\n",
    "    block = nixfile.create_block(\"Session 1\", \"nix.recording_session\")\n",
    "    data_array = block.create_data_array(\"multichannel_data\", \"nix.sampled.multichannel\", dtype=nixio.DataType.Double,\n",
    "                                         shape=(chunk_samples, number_of_channels), label=\"voltage\", unit=\"mV\")\n",
    "    data_array.append_sampled_dimension(0.001, label=\"time\", unit=\"s\")\n",
    "    data_array.append_set_dimension(labels=[\"channel %i\" % i for i in range(number_of_channels)])\n",
    "    \n",
    "    total_samples = chunk_count * chunk_samples\n",
    "    data = record_data(total_samples, number_of_channels, dt)\n",
    "    chunks_recorded = 0\n",
    "    t0 = time.time()\n",
    "    while chunks_recorded < chunk_count:\n",
    "        start_index = chunk_samples * chunks_recorded\n",
    "        if chunks_recorded == 0:\n",
    "            data_array.write_direct(data[start_index:start_index + chunk_samples, :])\n",
    "        else:\n",
    "            data_array.append(data[start_index:start_index+chunk_samples, :], axis=0)\n",
    "        chunks_recorded += 1\n",
    "    total_time = time.time() - t0\n",
    "\n",
    "    nixfile.close()\n",
    "    return total_time\n",
    "\n",
    "\n",
    "time_needed = write_nixfile(\"chunking_test.nix\", chunk_samples=100000, chunk_count=10)\n",
    "print(time_needed)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit"
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}